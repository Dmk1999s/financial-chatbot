import uuid
from openai import OpenAI
from dotenv import load_dotenv
import os
from langchain_core.messages import HumanMessage, AIMessage
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.runnables import RunnableLambda
from langchain_core.runnables.history import RunnableWithMessageHistory
from django.core.cache import cache
from django.contrib.auth.models import User
import re
import ast
import json
from functools import partial, lru_cache
from typing import Optional
from chat.constants.fields import REQUIRED_KEYS, REQUIRED_KEYS_ORDER, QUESTION_KO

load_dotenv()

# ìºì‹±ì„ ì´ìš©í•´ì„œ ìµœì í™”
class OptimizedOpenAIClient:
    def __init__(self):
        self.client = OpenAI(
            api_key=os.getenv("OPENAI_API_KEY"),
            max_retries=2,
            timeout=30.0
        )
    
    def create_completion(self, messages, model="gpt-3.5-turbo", **kwargs):
        # ë°˜ë³µë˜ëŠ” ì¿¼ë¦¬ê°€ ìˆìœ¼ë©´ ìºì‹œ ë¨¼ì € í™•ì¸
        prompt_str = str(messages)
        cache_key = f"gpt_response_{hash(prompt_str)}"
        cached = cache.get(cache_key)
        if cached:
            return cached
            
        response = self.client.chat.completions.create(
            model=model,
            messages=messages,
            **kwargs
        )
        
        # Cache for 5 minutes
        cache.set(cache_key, response, 300)
        return response

client = OptimizedOpenAIClient()
fine_tuned_model = "ft:gpt-3.5-turbo-0125:personal::BDpYRjbn"
store = {}

# ì„¸ì…˜ ì„ì‹œ ë°ì´í„°ëŠ” ìºì‹œì— ì €ì¥ (ê¸°ë³¸ì€ LocMemCache, ì¶”í›„ Redisë¡œ ì „í™˜ ê°€ëŠ¥)
# í‚¤ ê·œì•½:
# - ì„¸ì…˜ ë°ì´í„°: chat:session:{session_id}  (dict í˜•íƒœ)
# - ì¶©ëŒ ë³´ë¥˜:   chat:conflict_pending      (dict í˜•íƒœ, ê¸°ì¡´ ë™ì‘ ìœ ì§€)

def _session_key(session_id: str) -> str:
    return f"chat:session:{session_id}"

def get_session_data(session_id: str) -> dict:
    return cache.get(_session_key(session_id)) or {}

def set_session_data(session_id: str, data: dict) -> None:
    cache.set(_session_key(session_id), data, timeout=None)

def delete_session_data(session_id: str) -> None:
    cache.delete(_session_key(session_id))

def get_conflict_pending() -> Optional[dict]:
    return cache.get("chat:conflict_pending")

def set_conflict_pending_cache(data: dict) -> None:
    cache.set("chat:conflict_pending", data, timeout=600)

def pop_conflict_pending() -> Optional[dict]:
    data = cache.get("chat:conflict_pending")
    if data is not None:
        cache.delete("chat:conflict_pending")
    return data
# REQUIRED_KEYS / REQUIRED_KEYS_ORDER / QUESTION_KOëŠ” constants/fields.py ì°¸ì¡°

finetune_prompt = f"""
1. ë„ˆëŠ” ê¸ˆìœµìƒí’ˆ ì¶”ì²œ ì–´í”Œì— íƒ‘ì¬ëœ ì±—ë´‡ì´ë©°, ì´ë¦„ì€ 'ì±—ë´‡'ì´ë‹¤.
2. í•œêµ­ì–´ë¡œ ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•´ì•¼ í•œë‹¤.
3. ì‚¬ìš©ìì—ê²Œ ë‹¤ìŒ í•­ëª©ì„ ìˆœì„œëŒ€ë¡œ ë¬¼ì–´ë´ì•¼ í•œë‹¤:
- age: ë‚˜ì´ (ì •ìˆ˜)
- risk_tolerance: ìœ„í—˜ í—ˆìš© ì •ë„ (ì˜ˆ: ë‚®ìŒ, ì¤‘ê°„, ë†’ìŒ)
- monthly_income: ì›” ì†Œë“ (ì •ìˆ˜, ë‹¨ìœ„ëŠ” ì›)
- income_stability: ì†Œë“ ì•ˆì •ì„± (ì˜ˆ: ì•ˆì •ì , ë¶ˆì•ˆì •)
- income_sources: ì†Œë“ì› (ì˜ˆ: ì•„ë¥´ë°”ì´íŠ¸, ì›”ê¸‰ ë“±)
- investment_horizon: íˆ¬ì ê¸°ê°„ (ì •ìˆ˜, ë‹¨ìœ„ëŠ” ì¼)
- expected_return: ê¸°ëŒ€ ìˆ˜ìµ (ì •ìˆ˜, ë‹¨ìœ„ëŠ” ì›)
- expected_loss: ì˜ˆìƒ ì†ì‹¤ (ì •ìˆ˜, ë‹¨ìœ„ëŠ” ì›)
- investment_purpose: íˆ¬ì ëª©ì  (ì˜ˆ: ì•ˆì •ì ì¸ ì£¼ì‹ ì¶”ì²œ)
- asset_allocation_type: ìì‚° ë°°ë¶„ ìœ í˜• (0~4ì˜ ì •ìˆ˜. 0: 10% ë¯¸ë§Œ, 1: 10~20%, 2: 20~30%, 3: 30~40%, 4: 40% ì´ìƒ)
- value_growth: ê°€ì¹˜ ë˜ëŠ” ì„±ì¥ (0~1ì˜ ì •ìˆ˜. 0: ê°€ì¹˜, 1: ì„±ì¥)
- risk_acceptance_level: ìœ„í—˜ ìˆ˜ìš© ìˆ˜ì¤€ (1~4ì˜ ì •ìˆ˜. 1: ë¬´ì¡°ê±´ íˆ¬ìì›ê¸ˆ ë³´ì¡´, 2: ì´ììœ¨ ìˆ˜ì¤€ì˜ ìˆ˜ìµ ë° ì†ì‹¤ ê¸°ëŒ€, 3: ì‹œì¥ì— ë¹„ë¡€í•œ ìˆ˜ìµ ë° ì†ì‹¤ ê¸°ëŒ€, 4: ì‹œì¥ìˆ˜ìµë¥  ì´ˆê³¼ ìˆ˜ìµ ë° ì†ì‹¤ ê¸°ëŒ€) 
- investment_concern: íˆ¬ì ê´€ë ¨ ê³ ë¯¼ (ì˜ˆ: ì–´ë–¤ ì£¼ì‹ì„ ì‚´ì§€ ëª¨ë¦„)

4. ê° í•­ëª©ì„ ì‚¬ìš©ìê°€ ëª¨ë‘ ì‘ë‹µí•˜ë©´ "ì´ì œ ê¸ˆìœµìƒí’ˆì„ ì¶”ì²œí•´ì¤„ê²Œìš”!" ë¼ëŠ” ë§ì„ í•˜ë©° ëŒ€í™”ë¥¼ ëë‚¸ë‹¤.
"""

gpt_prompt = """
ë„ˆëŠ” ì˜¤ì§ JSON ê°ì²´ë§Œ ë°˜í™˜í•˜ëŠ” íŒŒì„œì•¼.
ì ˆëŒ€ ì§ˆë¬¸ì´ë‚˜ ëŒ€ë‹µ ì—†ì´ JSONë§Œ ì‘ë‹µí•´. ì´ ì™¸ì˜ í…ìŠ¤íŠ¸ëŠ” í—ˆìš©ë˜ì§€ ì•Šì•„.
ë‹¤ìŒì€ JSON ì˜ˆì‹œì•¼:
{
  "age": 25,
  "monthly_income": 4000000,
  "income_sources": "ì•„ë¥´ë°”ì´íŠ¸",
  "income_stability": "ë¶ˆì•ˆì •",
  "investment_horizon": 30,
  "expected_return": 300000,
  "expected_loss": 100000,
  "investment_purpose": "ë‹¨ê¸° ìˆ˜ìµ",
  "asset_allocation_type": 2,
  "value_growth": 1,
  "risk_acceptance_level": 3,
  "investment_concern": "ë¬´ìŠ¨ ì£¼ì‹ì„ ì‚¬ì•¼ í• ì§€ ëª¨ë¥´ê² ì–´ìš”",
  "risk_tolerance": "ì¤‘ê°„"
}
ëª¨ë“  í•­ëª©ì´ ì—†ì„ ê²½ìš°ì—ëŠ” ë°˜ë“œì‹œ ë¹ˆ ê°ì²´ë§Œ ì¶œë ¥í•´: {}
JSON ì™¸ì˜ ë¬¸ì¥ì´ í•œ ì¤„ì´ë¼ë„ ìˆìœ¼ë©´ ì˜¤ë¥˜ì•¼. ë°˜ë“œì‹œ ì§€ì¼œ.
"""

@lru_cache(maxsize=1000)
def get_cached_session_id():
    return str(uuid.uuid4())

def get_session_id(request_data):
    session_id = request_data.get("session_id")
    if not session_id:
        # ì²˜ìŒ ëŒ€í™”í•˜ëŠ” userì— ëŒ€í•´ì„œ ì„¸ì…˜ ë°œê¸‰
        username = request_data.get("username", "anonymous")
        session_id = f"new_{username}_{hash(str(request_data)) % 10000}"
    return session_id

def get_session_history(session_id: str):
    if session_id not in store:
        store[session_id] = ChatMessageHistory()
    return store[session_id]

def convert_history_to_openai_format(history):
    role_map = {"human": "user", "ai": "assistant", "system": "system"}
    return [{"role": role_map.get(msg.type, msg.type), "content": msg.content} for msg in history]

def check_conflict(current_data, new_fields):
    conflicting_fields = []
    for key, new_value in new_fields.items():
        if key in current_data and current_data[key] != new_value:
            conflicting_fields.append((key, current_data[key], new_value))
    return conflicting_fields




def extract_json_from_response(text: str):
    try:
        # ë°±í‹± ë¸”ëŸ­ ì œê±° (```json ~ ```)
        cleaned_text = re.sub(r"```json|```", "", text).strip()

        # ì¤‘ê´„í˜¸ ê°ì‹¸ì§„ JSON í…ìŠ¤íŠ¸ ì¶”ì¶œ
        match = re.search(r"\{.*\}", cleaned_text, re.DOTALL)
        if match:
            return json.loads(match.group())
        else:
            print("â— JSON í˜•ì‹ì´ ì•„ë‹˜. ì‘ë‹µ ì—†ìŒìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
            return {}
    except Exception:
        # íŒŒì‹± ì¤‘ ì—ëŸ¬ë‚˜ë©´ ë¹ˆ dict ë°˜í™˜
        return {}


def extract_fields_from_natural_response(response_text: str, session_id: str) -> dict:

    fields = {}
    text_lower = response_text.lower()
    
    # Age extraction
    age_match = re.search(r'(\d+)ì‚´|ë‚˜ì´.*?(\d+)|age.*?(\d+)', text_lower)
    if age_match:
        fields['age'] = int(age_match.group(1) or age_match.group(2) or age_match.group(3))
    
    # Monthly income extraction (ë§Œì› ë‹¨ìœ„ ë“±ì„ ì› ë‹¨ìœ„ë¡œ)
    income_match = re.search(r'(\d+)ë§Œì›|ì›”ê¸‰.*?(\d+)|ìˆ˜ì….*?(\d+)', text_lower)
    if income_match:
        fields['monthly_income'] = int(income_match.group(1) or income_match.group(2) or income_match.group(3)) * 10000
    
    # Risk tolerance
    if any(word in text_lower for word in ['ì•ˆì „', 'ë³´ìˆ˜ì ', 'ë‚®ìŒ']):
        fields['risk_tolerance'] = 'ë‚®ìŒ'
    elif any(word in text_lower for word in ['ì ê·¹ì ', 'ë†’ìŒ', 'ê³µê²©ì ']):
        fields['risk_tolerance'] = 'ë†’ìŒ'
    elif 'ì¤‘ê°„' in text_lower:
        fields['risk_tolerance'] = 'ì¤‘ê°„'
    
    return fields

def run_gpt(input_data, config, ai_model):
    user_input = input_data["input"]
    session_id = config.get("configurable", {}).get("session_id")
    user_id = config.get("configurable", {}).get("user_id")

    if user_input.strip() in ["ë„¤", "ì•„ë‹ˆì˜¤"] and get_conflict_pending() is not None:
        pending = pop_conflict_pending() or {}
        if user_input.strip() == "ë„¤":
            # ì¶©ëŒ í•­ëª©ì„ ì €ì¥
            current = get_session_data(session_id)
            current.update(pending)
            set_session_data(session_id, current)
            return {"output": "í”„ë¡œí•„ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤. ê³„ì† ì§„í–‰í• ê²Œìš”."}
        else:
            return {"output": "ê¸°ì¡´ í”„ë¡œí•„ ì •ë³´ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤. ê³„ì† ì§„í–‰í• ê²Œìš”."}

    # í˜„ì¬ ëˆ„ë½ëœ í•„ë“œ ì¶”ì 
    current_data = get_session_data(session_id)
    missing_keys = [key for key in REQUIRED_KEYS if key not in current_data or current_data[key] is None]

    # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ + ëˆ„ë½ëœ í‚¤ì— ëŒ€í•œ ì§ˆë¬¸ ìœ ë„
    base_prompt = input_data.get("system_prompt", finetune_prompt)
    prompt_addition = ""
    if missing_keys:
        prompt_addition = (
            "ì•„ì§ ìˆ˜ì§‘ë˜ì§€ ì•Šì€ ì •ë³´ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n"
            f"{', '.join(missing_keys)}\n"
            "ì´ ì •ë³´ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”ë¥¼ í†µí•´ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”. ì§ˆë¬¸ì€ ë°˜ë“œì‹œ í•œ ë²ˆì— í•˜ë‚˜ì”© í•˜ì„¸ìš”."
        )

    full_prompt = base_prompt + prompt_addition

    history = get_session_history(session_id).messages
    formatted_history = convert_history_to_openai_format(history)

    messages = [{"role": "system", "content": full_prompt}] + formatted_history + [
        {"role": "user", "content": user_input}
    ]

    response = client.create_completion(
        messages=messages,
        model=ai_model,
        temperature=0.0,
        max_tokens=150  # ì†ë„ë¥¼ ìœ„í•´ í† í° ì œí•œ
    )
    return {"output": response.choices[0].message.content}


def call_gpt_model(prompt: str, session_id: str) -> str:
    input_data = {
        "input": prompt,
        "system_prompt": gpt_prompt
    }

    config = {
        "configurable": {
            "session_id": session_id
        }
    }

    return _run_gpt_parser(input_data, config, "gpt-3.5-turbo")["output"]

def _run_gpt_parser(input_data, config, model):
    messages = [
        {"role": "system", "content": input_data["system_prompt"]},
        {"role": "user", "content": input_data["input"]}
    ]
    response = client.create_completion(
        messages=messages,
        model=model,
        temperature=0.0,
    )
    return {"output": response.choices[0].message.content}

run_gpt_with_model = partial(run_gpt, ai_model=fine_tuned_model)
# Runnable êµ¬ì„±
runnable = RunnableLambda(run_gpt_with_model)

with_message_history = RunnableWithMessageHistory(
    runnable,
    get_session_history,
    input_messages_key="input",
    history_messages_key="history"
)

"""
ì •ë³´ë¥¼ DBì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜
"""
def save_profile_from_gpt(parsed_data, user_id, session_id):
    print("DEBUG: save the data")
    try:
        user = User.objects.get(email=user_id)  # ê¸°ì¡´ ìœ ì € ì¡°íšŒ
        user.age = parsed_data.get("age")
        user.income_stability = parsed_data.get("income_stability")
        user.risk_tolerance = parsed_data.get("risk_tolerance")
        user.income_source = parsed_data.get("income_sources")
        # map new keys to model fields
        monthly_income = parsed_data.get("monthly_income")
        if monthly_income is not None:
            user.income = monthly_income
        investment_horizon = parsed_data.get("investment_horizon")
        if investment_horizon is not None:
            user.period = investment_horizon
        expected_return = parsed_data.get("expected_return")
        if expected_return is not None:
            user.expected_income = expected_return
        expected_loss = parsed_data.get("expected_loss")
        if expected_loss is not None:
            user.expected_loss = expected_loss
        investment_purpose = parsed_data.get("investment_purpose")
        if investment_purpose is not None:
            user.purpose = investment_purpose
        
        # direct mappings for remaining optional fields
        if parsed_data.get("asset_allocation_type") is not None:
            user.asset_allocation_type = parsed_data.get("asset_allocation_type")
        if parsed_data.get("value_growth") is not None:
            user.value_growth = parsed_data.get("value_growth")
        if parsed_data.get("risk_acceptance_level") is not None:
            user.risk_acceptance_level = parsed_data.get("risk_acceptance_level")
        if parsed_data.get("investment_concern") is not None:
            user.investment_concern = parsed_data.get("investment_concern")
        
        user.save()
        print(f"ğŸ” ì €ì¥ëœ user: {user.__dict__}")
    except Exception as e:
        print(f"DB ì €ì¥ ì‹¤íŒ¨: {e}")


"""
task.pyì— ì œê³µí•˜ëŠ” í•¨ìˆ˜
"""
def handle_chat(user_input, session_id, user_id=None):
    # ì„¸ì…˜ ì €ì¥ì†Œê°€ ì—†ìœ¼ë©´ ì´ˆê¸°í™”
    # ì„¸ì…˜ ì €ì¥ì†Œ ì´ˆê¸°í™”ëŠ” get/setë¡œ ëŒ€ì²´

    # ì‚¬ìš©ì í˜„ì¬ ì…ë ¥ì—ì„œ ìš°ì„  í•„ë“œë¥¼ ì¶”ì¶œí•˜ì—¬ ë°˜ì˜
    user_extracted = extract_fields_from_natural_response(user_input, session_id)
    if user_extracted:
        valid_fields = {k: v for k, v in user_extracted.items() if k in REQUIRED_KEYS and v is not None}
        if valid_fields:
            current = get_session_data(session_id)
            current.update(valid_fields)
            set_session_data(session_id, current)

    # ëˆ„ë½ëœ í‚¤(ì§ˆë¬¸í•´ì•¼ í•  í•­ëª©)ë¥¼ ìˆœì„œëŒ€ë¡œ ê³„ì‚°
    current_data = get_session_data(session_id)
    missing_ordered = [k for k in REQUIRED_KEYS_ORDER if k not in current_data or current_data.get(k) is None]

    # ì‹ ê·œ ì„¸ì…˜ì´ê±°ë‚˜ ìˆ˜ì§‘ ì¤‘ì´ë©´, ë‹¤ìŒ í•˜ë‚˜ì˜ ëˆ„ë½ í•­ëª©ë§Œ ì§ˆë¬¸ìœ¼ë¡œ ë°˜í™˜
    if session_id.startswith("new_") or missing_ordered:
        if missing_ordered:
            next_key = missing_ordered[0]
            return QUESTION_KO[next_key], session_id
        else:
            # ì˜ˆì™¸ ìƒí™©: ì¼ë°˜ ì¸ì‚¬ë¡œ í´ë°±
            return "ì•ˆë…•í•˜ì„¸ìš”! íˆ¬ì ìƒë‹´ì„ ë„ì™€ë“œë¦´ê²Œìš”.", session_id

    # ì—¬ê¸°ê¹Œì§€ ì™”ë‹¤ë©´ ëª¨ë“  í•­ëª©ì´ ì±„ì›Œì§„ ìƒíƒœ
    if REQUIRED_KEYS.issubset(current_data.keys()):
        if user_id:
            save_profile_from_gpt(current_data, user_id, session_id)
        delete_session_data(session_id)
        return "ì´ì œ ê¸ˆìœµìƒí’ˆì„ ì¶”ì²œí•´ì¤„ê²Œìš”!", session_id

    # í•„ìš” ì‹œ ëª¨ë¸ ê¸°ë°˜ ëŒ€í™”ë¡œ í´ë°±
    result = with_message_history.invoke(
        {"input": user_input},
        config={"configurable": {"session_id": session_id}}
    )
    gpt_reply = result["output"]

    extracted_fields = extract_fields_from_natural_response(gpt_reply, session_id)
    if extracted_fields:
        valid_fields = {k: v for k, v in extracted_fields.items() if k in REQUIRED_KEYS and v is not None}
        current = get_session_data(session_id)
        current.update(valid_fields)
        set_session_data(session_id, current)

    current_data = get_session_data(session_id)
    if REQUIRED_KEYS.issubset(current_data.keys()):
        if user_id:
            save_profile_from_gpt(current_data, user_id, session_id)
        delete_session_data(session_id)

    return gpt_reply, session_id


# ==========================================================
# âœ… ì¼ë°˜ ëŒ€í™” ì²˜ë¦¬ë¥¼ ìœ„í•œ í•¨ìˆ˜ ì¶”ê°€
# ==========================================================
def handle_chitchat(query: str) -> str:
    """
    RAG ê²€ìƒ‰ ì—†ì´ ì¼ë°˜ì ì¸ ëŒ€í™”ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    """
    openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    response = openai_client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ì¹œì ˆí•œ ê¸ˆìœµ ìƒë‹´ ì±—ë´‡ì…ë‹ˆë‹¤."},
            {"role": "user", "content": query}
        ],
        temperature=0.7,
        max_tokens=500
    )
    return response.choices[0].message.content