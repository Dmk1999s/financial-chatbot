import uuid
from openai import OpenAI
from dotenv import load_dotenv
import os
from langchain_core.messages import HumanMessage, AIMessage
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.runnables import RunnableLambda
from langchain_core.runnables.history import RunnableWithMessageHistory
from main.models import User
from functools import partial
import re
import ast
import json
import openai


load_dotenv()

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
fine_tuned_model = "ft:gpt-3.5-turbo-0125:personal::BDpYRjbn"
store = {}
SESSION_TEMP_STORE = {}  # session_id: dict

REQUIRED_KEYS = {
    "age", "risk_tolerance", "income_stability", "income_sources",
    "income", "period", "expected_income", "expected_loss",
    "purpose", "value_growth",
    "risk_acceptance_level", "investment_concern"
}

prompt = f"""
1. ë„ˆëŠ” ê¸ˆìœµìƒí’ˆ ì¶”ì²œ ì–´í”Œì— íƒ‘ì¬ëœ ì±—ë´‡ì´ë©°, ì´ë¦„ì€ 'ì±—ë´‡'ì´ë‹¤.
2. í•œêµ­ì–´ë¡œ ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•´ì•¼ í•œë‹¤.
3. ì‚¬ìš©ìì—ê²Œ ë‹¤ìŒ í•­ëª©ì„ ìˆœì„œëŒ€ë¡œ ë¬¼ì–´ë´ì•¼ í•œë‹¤:
- age: ë‚˜ì´ (ì •ìˆ˜)
- risk_tolerance: ìœ„í—˜ í—ˆìš© ì •ë„ (ì˜ˆ: ë‚®ìŒ, ì¤‘ê°„, ë†’ìŒ)
- income: ì—°ì†Œë“ (ì •ìˆ˜, ë‹¨ìœ„ëŠ” ì›)
- income_stability: ì†Œë“ ì•ˆì •ì„± (ì˜ˆ: ì•ˆì •ì , ë¶ˆì•ˆì •)
- income_sources: ì†Œë“ì› (ì˜ˆ: ì•„ë¥´ë°”ì´íŠ¸, ì›”ê¸‰ ë“±)
- period: íˆ¬ì ê¸°ê°„ (ì˜ˆ: ì •ìˆ˜, ë‹¨ìœ„ëŠ” ì¼)
- expected_income: ê¸°ëŒ€ ìˆ˜ìµ (ì •ìˆ˜, ë‹¨ìœ„ëŠ” ì›)
- expected_loss: ì˜ˆìƒ ì†ì‹¤ (ì •ìˆ˜, ë‹¨ìœ„ëŠ” ì›)
- purpose: íˆ¬ì ëª©ì  (ì˜ˆ: ì•ˆì •ì ì¸ ì£¼ì‹ ì¶”ì²œ)
- asset_allocation_type: ìì‚° ë°°ë¶„ ìœ í˜• (0~4ì˜ ì •ìˆ˜. 0: 10% ë¯¸ë§Œ, 1: 10~20%, 2: 20~30%, 3: 30~40%, 4: 40% ì´ìƒ)
- value_growth: ê°€ì¹˜ ë˜ëŠ” ì„±ì¥ (0~1ì˜ ì •ìˆ˜. 0: ê°€ì¹˜, 1: ì„±ì¥)
- risk_acceptance_level: ìœ„í—˜ ìˆ˜ìš© ìˆ˜ì¤€ (1~4ì˜ ì •ìˆ˜. 1: ë¬´ì¡°ê±´ íˆ¬ìì›ê¸ˆ ë³´ì¡´, 2: ì´ììœ¨ ìˆ˜ì¤€ì˜ ìˆ˜ìµ ë° ì†ì‹¤ ê¸°ëŒ€, 3: ì‹œì¥ì— ë¹„ë¡€í•œ ìˆ˜ìµ ë° ì†ì‹¤ ê¸°ëŒ€, 4: ì‹œì¥ìˆ˜ìµë¥  ì´ˆê³¼ ìˆ˜ìµ ë° ì†ì‹¤ ê¸°ëŒ€) 
- investment_concern: íˆ¬ì ê´€ë ¨ ê³ ë¯¼ (ì˜ˆ: ì–´ë–¤ ì£¼ì‹ì„ ì‚´ì§€ ëª¨ë¦„)

4. ê° í•­ëª©ì„ ì‚¬ìš©ìê°€ ëª¨ë‘ ì‘ë‹µí•˜ë©´ "ì´ì œ ê¸ˆìœµìƒí’ˆì„ ì¶”ì²œí•´ì¤„ê²Œìš”!" ë¼ëŠ” ë§ì„ í•˜ë©° ëŒ€í™”ë¥¼ ëë‚¸ë‹¤.
"""

def get_session_id(request_data):
    return request_data.get("session_id", str(uuid.uuid4()))

def get_session_history(session_id: str):
    if session_id not in store:
        store[session_id] = ChatMessageHistory()
    return store[session_id]

def convert_history_to_openai_format(history):
    role_map = {"human": "user", "ai": "assistant", "system": "system"}
    return [{"role": role_map.get(msg.type, msg.type), "content": msg.content} for msg in history]

def has_required_keys(parsed: dict) -> bool:
    return all(k in parsed and parsed[k] is not None for k in REQUIRED_KEYS)

def run_gpt(input_data, config, ai_model):
    user_input = input_data["input"]
    session_id = config.get("configurable", {}).get("session_id")

    # í˜„ì¬ ëˆ„ë½ëœ í•„ë“œ ì¶”ì 
    missing_keys = []
    if session_id in SESSION_TEMP_STORE:
        current_data = SESSION_TEMP_STORE[session_id]
        missing_keys = [key for key in REQUIRED_KEYS if key not in current_data or current_data[key] is None]

    # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ + ëˆ„ë½ëœ í‚¤ì— ëŒ€í•œ ì§ˆë¬¸ ìœ ë„
    base_prompt = input_data.get("system_prompt", prompt)
    prompt_addition = ""
    if missing_keys:
        prompt_addition = (
            "ì•„ì§ ìˆ˜ì§‘ë˜ì§€ ì•Šì€ ì •ë³´ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n"
            f"{', '.join(missing_keys)}\n"
            "ì´ ì •ë³´ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”ë¥¼ í†µí•´ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”. ì§ˆë¬¸ì€ ë°˜ë“œì‹œ í•œ ë²ˆì— í•˜ë‚˜ì”© í•˜ì„¸ìš”."
        )

    full_prompt = base_prompt + prompt_addition

    history = get_session_history(session_id).messages
    formatted_history = convert_history_to_openai_format(history)

    messages = [{"role": "system", "content": full_prompt}] + formatted_history + [
        {"role": "user", "content": user_input}
    ]

    response = client.chat.completions.create(
        model=ai_model,
        messages=messages,
        temperature=0.0,
    )
    return {"output": response.choices[0].message.content}


def call_gpt_model(prompt: str, session_id: str) -> str:
    input_data = {
        "input": prompt,
        "system_prompt": (
                "ë„ˆëŠ” ì˜¤ì§ JSON ê°ì²´ë§Œ ë°˜í™˜í•˜ëŠ” íŒŒì„œì•¼.\n"
                "ì ˆëŒ€ ì§ˆë¬¸ì´ë‚˜ ì„¤ëª… ì—†ì´ JSONë§Œ ì‘ë‹µí•´. ì´ ì™¸ì˜ í…ìŠ¤íŠ¸ëŠ” í—ˆìš©ë˜ì§€ ì•Šì•„.\n"
                "ë‹¤ìŒì€ JSON ì˜ˆì‹œì•¼:\n"
                "{\n"
                "  \"age\": 25,\n"
                "  \"income\": 4000000,\n"
                "  \"income_sources\": \"ì•„ë¥´ë°”ì´íŠ¸\",\n"
                "  \"income_stability\": \"ë¶ˆì•ˆì •\",\n"
                "  \"period\": 30,\n"
                "  \"expected_income\": 300000,\n"
                "  \"expected_loss\": 100000,\n"
                "  \"purpose\": \"ë‹¨ê¸° ìˆ˜ìµ\",\n"
                "  \"asset_allocation_type\": 2,\n"
                "  \"value_growth\": 1,\n"
                "  \"risk_acceptance_level\": 3,\n"
                "  \"investment_concern\": \"ë¬´ìŠ¨ ì£¼ì‹ì„ ì‚¬ì•¼ í• ì§€ ëª¨ë¥´ê² ì–´ìš”\",\n"
                "  \"risk_tolerance\": \"ì¤‘ê°„\"\n"
                "}\n"
                "ëª¨ë“  í•­ëª©ì´ ì—†ì„ ê²½ìš°ì—ëŠ” ë°˜ë“œì‹œ ë¹ˆ ê°ì²´ì¸ `{}` ë§Œ ì¶œë ¥í•´.\n"
                "JSON ì™¸ì˜ ë¬¸ì¥ì´ í•œ ì¤„ì´ë¼ë„ ìˆìœ¼ë©´ ì˜¤ë¥˜ì•¼. ë°˜ë“œì‹œ ì§€ì¼œ.\n"
        )
    }

    config = {
        "configurable": {
            "session_id": session_id
        }
    }

    return run_gpt(input_data, config, "gpt-3.5-turbo")["output"]

def extract_json_from_response(response_text: str) -> dict:
    try:
        # ì¤‘ê´„í˜¸ë¡œ ë‘˜ëŸ¬ì‹¸ì¸ JSON ë¸”ë¡ ì¶”ì¶œ
        json_text = re.search(r'{.*}', response_text, re.DOTALL).group()
        print(f"â— JSON ì¶”ì¶œ ê²°ê³¼: {json.loads(json_text)}")
        return json.loads(json_text)
    except Exception as e:
        print(f"â— JSON ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return {}

def extract_fields_from_natural_response(response_text: str, session_id: str) -> dict:
    gpt_raw = call_gpt_model(response_text, session_id)
    print("ğŸ“¥ GPT raw repr:", repr(gpt_raw))
    print("ğŸ“¥ GPT ì‘ë‹µ:", gpt_raw)

    try:
        match = re.search(r'\{.*\}', gpt_raw, re.DOTALL)
        if match:
            json_text = match.group().strip()
            parsed = json.loads(json_text)
            print(f"âœ… íŒŒì‹±ëœ JSON: {parsed}")
            (print(type(parsed)))
            return parsed
        else:
            print("â— JSON í˜•ì‹ì´ ì•„ë‹˜. ì‘ë‹µ ì—†ìŒìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
            return {}
    except Exception as e:
        print(f"â— ì˜ˆì™¸ ë°œìƒ: {e}")
        return {}

run_gpt_with_model = partial(run_gpt, ai_model=fine_tuned_model)
# Runnable êµ¬ì„±
runnable = RunnableLambda(run_gpt_with_model)

with_message_history = RunnableWithMessageHistory(
    runnable,
    get_session_history,
    input_messages_key="input",
    history_messages_key="history"
)

"""
ì •ë³´ë¥¼ DBì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜
"""
def save_profile_from_gpt(parsed_data, user_id, session_id):
    print("DEBUG: save the data")
    try:
        user = User.objects.get(email=user_id)  # ê¸°ì¡´ ìœ ì € ì¡°íšŒ
        user.age = parsed_data.get("age")
        user.income_stability = parsed_data.get("income_stability")
        user.expected_loss = parsed_data.get("expected_loss")
        #session_id=session_id,
        user.risk_tolerance=parsed_data.get("risk_tolerance")
        user.income_source=parsed_data.get("income_sources")
        user.income=parsed_data.get("income")
        user.period=parsed_data.get("period")
        user.expected_income=parsed_data.get("expected_income")
        user.expected_loss=parsed_data.get("expected_loss")
        user.purpose=parsed_data.get("purpose")
        user.save()
        print(f"ğŸ” ì €ì¥ëœ user: {user.__dict__}")
    except Exception as e:
        print(f"DB ì €ì¥ ì‹¤íŒ¨: {e}")


"""
views.pyì— ì œê³µí•˜ëŠ” í•¨ìˆ˜
"""
def handle_chat(user_input, session_id, user_id=None):
    result = with_message_history.invoke(
        {"input": user_input},
        config={"configurable": {"session_id": session_id}}
    )

    gpt_reply = result["output"]

    extracted_fields = extract_fields_from_natural_response(gpt_reply, session_id)

    if session_id not in SESSION_TEMP_STORE:
        SESSION_TEMP_STORE[session_id] = {}

    # ëˆ„ì  ì €ì¥ (None ê°’ + ì˜¤íƒ€ í‚¤ ì œê±°)
    valid_fields = {
        k: v for k, v in extracted_fields.items()
        if k in REQUIRED_KEYS and v is not None
    }
    SESSION_TEMP_STORE[session_id].update(valid_fields)

    current_data = SESSION_TEMP_STORE[session_id]

    # ëª¨ë“  í•„ë“œê°€ ëª¨ì´ë©´ ì €ì¥
    if REQUIRED_KEYS.issubset(current_data.keys()):
        if user_id:
            save_profile_from_gpt(current_data, user_id, session_id)
        del SESSION_TEMP_STORE[session_id]  # ì €ì¥ í›„ ì´ˆê¸°í™”

    return gpt_reply, session_id