import uuid
from openai import OpenAI
from dotenv import load_dotenv
import os
from langchain_core.messages import HumanMessage, AIMessage
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.runnables import RunnableLambda
from langchain_core.runnables.history import RunnableWithMessageHistory
from naughtyDjango.models import User
import re
import json
from django.db import transaction


load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
fine_tuned_model = "ft:gpt-3.5-turbo-0125:personal::BDpYRjbn"
store = {}

def get_session_id(request_data):
    return request_data.get("session_id", str(uuid.uuid4()))

def get_session_history(session_id: str):
    if session_id not in store:
        store[session_id] = ChatMessageHistory()
    return store[session_id]

def convert_history_to_openai_format(history):
    role_map = {"human": "user", "ai": "assistant", "system": "system"}
    return [{"role": role_map.get(msg.type, msg.type), "content": msg.content} for msg in history]
prompt = f"""
1. ë„ˆëŠ” ê¸ˆìœµìƒí’ˆ ì¶”ì²œ ì–´í”Œì— íƒ‘ì¬ëœ ì±—ë´‡ì´ë©°, ì´ë¦„ì€ 'ì±—ë´‡'ì´ë‹¤.
2. í•œêµ­ì–´ë¡œ ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•´ì•¼ í•œë‹¤.
3. ì‚¬ìš©ìì—ê²Œ ë‹¤ìŒ í•­ëª©ì„ ìˆœì„œëŒ€ë¡œ ë¬¼ì–´ë´ì•¼ í•œë‹¤:
- age: ë‚˜ì´ (ì •ìˆ˜)
- risk_tolerance: ìœ„í—˜ í—ˆìš© ì •ë„ (ì˜ˆ: ë‚®ìŒ, ì¤‘ê°„, ë†’ìŒ)
- income: ì—°ì†Œë“ (ì •ìˆ˜, ë‹¨ìœ„ëŠ” ì›)
- income_stability: ì†Œë“ ì•ˆì •ì„± (ì˜ˆ: ì•ˆì •ì , ë¶ˆì•ˆì •)
- income_sources: ì†Œë“ì› (ì˜ˆ: ì•„ë¥´ë°”ì´íŠ¸, ì›”ê¸‰ ë“±)
- period: íˆ¬ì ê¸°ê°„ (ì˜ˆ: ì •ìˆ˜, ë‹¨ìœ„ëŠ” ì¼)
- expected_income: ê¸°ëŒ€ ìˆ˜ìµ (ì •ìˆ˜, ë‹¨ìœ„ëŠ” ì›)
- expected_loss: ì˜ˆìƒ ì†ì‹¤ (ì •ìˆ˜, ë‹¨ìœ„ëŠ” ì›)
- purpose: íˆ¬ì ëª©ì  (ì˜ˆ: ì•ˆì •ì ì¸ ì£¼ì‹ ì¶”ì²œ)
- asset_allocation_type: ìì‚° ë°°ë¶„ ìœ í˜• (0~4ì˜ ì •ìˆ˜. 0: 10% ë¯¸ë§Œ, 1: 10~20%, 2: 20~30%, 3: 30~40%, 4: 40% ì´ìƒ)
- value_growth: ê°€ì¹˜ ë˜ëŠ” ì„±ì¥ (0~1ì˜ ì •ìˆ˜. 0: ê°€ì¹˜, 1: ì„±ì¥)
- risk_acceptance_level: ìœ„í—˜ ìˆ˜ìš© ìˆ˜ì¤€ (1~4ì˜ ì •ìˆ˜. 1: ë¬´ì¡°ê±´ íˆ¬ìì›ê¸ˆ ë³´ì¡´, 2: ì´ììœ¨ ìˆ˜ì¤€ì˜ ìˆ˜ìµ ë° ì†ì‹¤ ê¸°ëŒ€, 3: ì‹œì¥ì— ë¹„ë¡€í•œ ìˆ˜ìµ ë° ì†ì‹¤ ê¸°ëŒ€, 4: ì‹œì¥ìˆ˜ìµë¥  ì´ˆê³¼ ìˆ˜ìµ ë° ì†ì‹¤ ê¸°ëŒ€) 
- investment_concern: íˆ¬ì ê´€ë ¨ ê³ ë¯¼ (ì˜ˆ: ì–´ë–¤ ì£¼ì‹ì„ ì‚´ì§€ ëª¨ë¦„)

4. ê° í•­ëª©ì„ ì‚¬ìš©ìê°€ ëª¨ë‘ ì‘ë‹µí•˜ë©´ ì•„ë˜ JSONí˜•ì‹ìœ¼ë¡œ ëª¨ë“  ì •ë³´ë¥¼ ì •ë¦¬í•´ì„œ ë³´ì—¬ì¤˜ì•¼ í•œë‹¤.
    {{
        "age": <int>,
        "risk_tolerance": "<string>",
        "income_stability": "<string>",
        "income_sources": "<string>",
        "income": <int>,
        "period": "<int>",
        "expected_income": "<int>",
        "expected_loss": "<int>",
        "purpose": "<string>",
        "asset_allocation_type": "<int>",
        "value_growth": "<int>",
        "risk_acceptance_level": "<int>",
        "investment_concern": "<string>",
    }}
"""


def run_gpt(input_data, config):
    user_input = input_data["input"]
    system_prompt = input_data.get("system_prompt", prompt)

    session_id = config.get("configurable", {}).get("session_id")
    history = get_session_history(session_id).messages
    formatted_history = convert_history_to_openai_format(history)

    messages = [{"role": "system", "content": system_prompt}] + formatted_history + [
        {"role": "user", "content": user_input}
    ]

    response = client.chat.completions.create(
        model=fine_tuned_model,
        messages=messages
    )
    return {"output": response.choices[0].message.content}

def extract_json_from_response(text: str):
    try:
        cleaned_text = re.sub(r"```json|```", "", text).strip()

        match = re.search(r"\{.*\}", cleaned_text, re.DOTALL)
        if match:
            json_str = match.group()
            return json.loads(json_str)
        else:
            print("[âš ï¸] JSON í˜•ì‹ì´ ì•„ë‹˜")
            return {}
    except Exception as e:
        return {}

# Runnable êµ¬ì„±
runnable = RunnableLambda(run_gpt)

with_message_history = RunnableWithMessageHistory(
    runnable,
    get_session_history,
    input_messages_key="input",
    history_messages_key="history"
)

"""
ì •ë³´ë¥¼ DBì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜
"""
def save_profile_from_gpt(parsed_data, user_id, session_id):
    print("DEBUG: save the data")
    try:
        user = User.objects.get(email=user_id)  # ê¸°ì¡´ ìœ ì € ì¡°íšŒ
        user.age = parsed_data.get("age")
        user.income_stability = parsed_data.get("income_stability")
        user.expected_loss = parsed_data.get("expected_loss")
        #session_id=session_id,
        user.risk_tolerance=parsed_data.get("risk_tolerance")
        user.income_source=parsed_data.get("income_sources")
        user.income=parsed_data.get("income")
        user.period=parsed_data.get("period")
        user.expected_income=parsed_data.get("expected_income")
        user.expected_loss=parsed_data.get("expected_loss")
        user.purpose=parsed_data.get("purpose")
        user.save()
        print(f"ğŸ” ì €ì¥ëœ user: {user.__dict__}")
    except Exception as e:
        print(f"DB ì €ì¥ ì‹¤íŒ¨: {e}")


"""
views.pyì— ì œê³µí•˜ëŠ” í•¨ìˆ˜
"""
def handle_chat(user_input, session_id, user_id=None):
    result = with_message_history.invoke(
        {"input": user_input},
        config={"configurable": {"session_id": session_id}}
    )
    gpt_reply = result["output"]


    if "{" in gpt_reply and "}" in gpt_reply:
        parsed = extract_json_from_response(gpt_reply)

        required_keys = [
            "age", "risk_tolerance", "income_stability", "income_sources",
            "income", "period", "expected_income", "expected_loss",
            "purpose", "asset_allocation_type", "value_growth",
            "risk_acceptance_level", "investment_concern"
        ]

        if all(k in parsed and parsed[k] is not None for k in required_keys):
            if user_id:
                save_profile_from_gpt(parsed, user_id, session_id)

    return gpt_reply, session_id